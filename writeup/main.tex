
\title{
	Neural Network Image Recognition Applied to Autonomous Quadcopters
}

\author{
	Asher Mancinelli \\
	Sophomore
	\and
	Davis Mariotti \\
	Senior
	\and 
	Whitworth University \\
	Department of Computer Science \\
	CS 457 - Artificial Intelligence 
}

\date{\today}

\documentclass[12pt]{article}
\usepackage{graphicx}
\graphicspath{ {images/} }
\usepackage{nomencl}
\makenomenclature
\usepackage{inputenc}

\begin{document}
\maketitle

\begin{abstract}

{
	\it Neural networks and autonomous vehicles have seen a large spike in developement in the last 10 years, and are often used in tandem. We attempted to merge the two fields through an image classification neural network used to control a quadcopter autonomously. 
}

\end{abstract}

\mbox{}

\nomenclature{NN}{ Neural Network: mathematic concept through which perceptrons are layered together and adjusted with sample data. }

\nomenclature{TF}{ TensorFlow: a library built by Google for in-house neural network computations and large matrix calculations. Written in C, but most often used via a Python wrapper. }

\nomenclature{Keras}{ Library built to run with a backend of Tensorflow or another low-level matrix-multliplecation library. Has higher level abstractions, such that the arcitecture of the neural network can be more consisely built.}

\printnomenclature

\section{Goal}
{

	\quad To create a program to interface a neural network (NN) such that our quadcopter will take off and fly in the direction of our target. The NN will take images from the quadcopter and classify them into the correct command to make the quadcopter follow the cube as it moves.
	\quad The classification will then be converted into commands that the quadcopter can interpret and sent to the quadcopter.

}

\section{Classification Methods}
{

	\quad One of the primary methods employed by software programmers to control vehicles autonomously is artificial intelligence, a subfield of which is neural networks. To autonomously control a quadcopter, we used a specific NN framework, Tensorflow (TF). \newline

	\quad The most notable drawback of using a NN is that it requires a very large data set for training. In order to create a dataset large enough to effectively train the NN, we wrote a script to take all the image data from the quadcopter while in flight. We then took our target object, a neon yellow-green cube, and walked it back at varying places relative to the quadcopter as we flew the quadcopter a rough 6 feet away from the target (see Figure 1: Training Method). 	
	

	\begin{figure}[h]
	\centering
	\includegraphics[scale=0.3]{quad-image}
	\caption{Training Method}
	\end{figure}

	\quad By varying the locations the cube is held at relative to the quadcopter, we obtained image training data assorted into the following categories representing the intended course of action the quadcopter should take:

	\begin{itemize}
		\item Forward
		\item Left
		\item Right
		\item No Action
	\end{itemize}

	\quad Element 1 of Figure 1 shows the position relative to the quadcopter (red circle) that the cube (green square) is held when we obtain the training data for the Straight category. 
	This is because the course of action the quadcopter should take is determined by where the cube is in the quadcopter's field of vision. 
	Thus, the category for element 2 will be Right, element 3 is Left, and the No Action category is just a quadcopter view without the target at all. 
	The images will be downsized to $32x32px$, and used to train the NN to classify images from the quadcopter's feed. \newline

	\quad In production, the process will work as follows:
	
	\begin{enumerate}
		\item{Quadcopter takes image}
		\item{Image is sent to paired computer}
		\item{Image is downsized to $32x32px$}
		\item{Image is passed through the trained NN}
		\item{Resulting classification is translated to quadcopter instruction}
		\item{Quadcopter instruction is sent to and executed by quadcopter}	
		\item{Return to step 1}
	\end{enumerate}
	
	\quad In this way, the quadcopter will act autonomously, although paired with another computer. 
	However, given the small file size of the project, it would be feasable to port the NN and scripts to run it onto the board of a quadcopter, such that it could drive itself autonomously, without being paired with another computer.

}

\section{Arcitecture}
{

	\quad The arcitecture of our NN is built on the keras.models.Sequential model, with three sections of layers, followed by a final section which converts the network to output and introduces dropout. The arcitecture of our NN is as follows: 

	\begin{itemize}
		\item{Section 1:}
		\begin{itemize}
			\item{2 Dimensional Convolutional layer} 
			\item{Relu Activation layer}
			\item{2 Dimensional Max Pooling layer}
		\end{itemize}
		\item{Section 2:}
		\begin{itemize}
			\item{2 Dimensional Convolutional layer} 
			\item{Relu Activation layer}
			\item{2 Dimensional Max Pooling layer}
		\end{itemize}
		\item{Section 3:}
		\begin{itemize}
			\item{2 Dimensional Convolutional layer} 
			\item{Relu Activation layer}
			\item{2 Dimensional Max Pooling layer}
		\end{itemize}
		\item{Section 4:}
		\begin{itemize}
			\item{Flatten layers}
			\item{Densely connected layer}
			\item{Relu Activation layer}
			\item{Dropout with 50\% dropout}
			\item{Densely connected layer}
			\item{Sigmoid Activation layer}
		\end{itemize}
	\end{itemize}
}

\section{Problems We Faced}
{
	We ran into a countless number of problems with both ends of this project, and each of us had to work through elements on our own and as a team.
	One of the biggest problems we ran into was the image handling system of the library we used. 
	OpenCV2 for Python only allows you to take a buffer of images, and does not allow any skips. 
	Davis overcame this by placing all the images into a last-in-last-out queue to grab the latest image.  
	I also ran into problems trying to get the model to compile and train efficiently , and how to save the model such that it can be loaded and used quickly enough for the controller to classify and send instructions to the drone. 
	Parrot, the manufactorer of our drone, also pushed a firmware update which essentially broke the entire library which we used for controlling our drone, which has understandably caused lots of problems. 
}

\section{Conclusions}
{
	This project was interesting because of the lack of resources to draw from.
	There were some other generic image classification examples online, for example the online documentation for Keras and Tensorflow. 
	We ended up simply adapting the methods used there to our situation. 
	The lack of resources drove us to innovate in many areas, often relying simply on our intuition and experience. 
	For example, Davis had to rewrite some of the code to connect with the drone and get images from it, and I had to reshape and alter the training images in order to get the classifier to work. 
	I also had to research how to compile our model for use in a method that our drone controller could use.
}

\end{document}
